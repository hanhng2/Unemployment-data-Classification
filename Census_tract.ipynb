{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "This notebook is meant as a comprehensive beginner's guide to creating a model using unsupervised algorithms. It explores how to cluster census tracts based on data collected from the US Census API, and includes both Python code and a running commentary.\n",
    "\n",
    "## Table of Contents\n",
    "Feature Sourcing --> what census tracts are; how to pull demographic data from the API\n",
    "\n",
    "Exploratory Data Analysis --> get a feel for the data, combine/drop features\n",
    "\n",
    "Feature Engineering --> process the data (transform, scale, standardize, impute)\n",
    "\n",
    "Dimensionality Reduction --> reduce correlations & computation time\n",
    "\n",
    "KMeans / Agglomerative --> actually assign census tracts to clusters\n",
    "\n",
    "Cluster Profiles --> identify what each cluster's characteristics are\n",
    "\n",
    "Validation --> use heatmap of the US to assess clustering performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Feature Sourcing\n",
    "\n",
    "## A. Overview\n",
    "A census tract is 11 numbers long and composed of three different FIPS codes: state, county and tract (the full 15 numbers is a census block, which is even more granular).\n",
    "\n",
    "There are 74K census tracts in the entire United States, and each one contains an average of several thousand people. As a result, the physical size of census tracts range widely depending on the population density of a given area.\n",
    "\n",
    "A full list of US state and county FIPS codes can be found here.\n",
    "\n",
    "State FIPS Codes\n",
    "There are 61 state-level FIPS codes in total because US territories also have FIPS codes.\n",
    "\n",
    "Specifically, state codes 03, 07, 11, 14, 43, 52 or anything above 56 do not represent states and will be excluded from our example below. Alaska (02) and Hawaii (15) will also be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. US Census API\n",
    "The US Census Bureau has an API with a lot of publicly available data.\n",
    "\n",
    "The API is open-source and provides the flexibility to pull data at various levels of aggregation.\n",
    "\n",
    "How to find & pull data from the API\n",
    "You can query a group at various levels of geographical area (state, zip code, census tract, etc.) - the full list of options can be found here\n",
    "The full list of data groups available (as of Dec. 2020) can be found here\n",
    "Once you have identified a group you'd like to pull, view the available reports using this link:\n",
    " https://api.census.gov/data/2019/acs/acs5/groups/{group}.html\n",
    " \n",
    "(1) To download a specific report onto your computer, open the terminal and run the following (note that the query parameters will need to be changed depending on the group and geo levels you'd like to pull):\n",
    "\n",
    "curl https://api.census.gov/data/2019/acs/acs5\\?get\\=NAME,{group}\\&for\\=tract:\\*\\&in\\=state:\\{state_fips_code}\\&in\\=county:\\* > {group}_zip.json\n",
    "\n",
    "(2) Open the downloaded report in a text editor by running: open {group}_zip.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Example¶\n",
    "Let's pull down all the reports for group B05004 which contains data on median age.\n",
    "\n",
    "To do this we'll need to generate:\n",
    "\n",
    "A list of state FIPS codes for the states we'd like to pull\n",
    "\n",
    "A list of the specific report names within each group we'd like to pull\n",
    "\n",
    "URLs for the API calls based on the report names and state FIPs codes\n",
    "\n",
    "We'll then run a script which makes the API calls, parses and saves the responses in a Pandas dataframe, and combines all the reports together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"B23001_001E\": Total population  \n",
    "\"B23001_005E\": Total unemployed  \n",
    "\"B23001_002E\": Total population in labor force  \n",
    "\"B23001_006E\": Total unemployment in labor force  \n",
    "\"B23001_003E\": Total male in labor force  \n",
    "\"B23001_007E\": Total unemployment of male in labor force  \n",
    "\"B23001_014E\": Total female in labor force  \n",
    "\"B23001_018E\": Total unemployment of female in labor force  \n",
    "\"B23001_003E\": White alone, in labor force  \n",
    "\"B23001_004E\": Black or African American alone, in labor force  \n",
    "\"B23001_005E\": American Indian and Alaska Native alone, in labor force  \n",
    "\"B23001_006E\": Asian alone, in labor force  \n",
    "\"B23001_007E\": Native Hawaiian and Other Pacific Islander alone, in labor force  \n",
    "\"B23001_008E\": Some other race alone, in labor force  \n",
    "\"B23001_009E\": Two or more races, in labor force  \n",
    "\"B23001_010E\": White alone, unemployed, in labor force  \n",
    "\"B23001_011E\": Black or African American alone, unemployed, in labor force  \n",
    "\"B23001_012E\": American Indian and Alaska Native alone, unemployed, in labor force  \n",
    "\"B23001_013E\": Asian alone, unemployed, in labor force  \n",
    "\"B23001_014E\": Native Hawaiian and Other Pacific Islander alone, unemployed, in labor force  \n",
    "\"B23001_015E\": Some other race alone, unemployed, in labor force  \n",
    "\"B23001_016E\": Two or more races, unemployed, in labor force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this in Anaconda base environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of State FIPS Codes: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['01', '04', '05', '06', '08']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of US state FIPS codes\n",
    "state_codes = [\n",
    "    str(elem).zfill(2) \n",
    "    for elem in list(range(1, 57)) \n",
    "    if elem not in (2, 3, 7, 11, 14, 15, 43, 52)\n",
    "]\n",
    "print(\"# of State FIPS Codes:\", len(state_codes))\n",
    "state_codes[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The groups you mentioned are part of the U.S. Census Bureau’s American Community Survey (ACS) data. Here’s what each of them represents:\n",
    "\n",
    "B05004_001E: This represents the total estimate for the median age by nativity and citizenship status by sex\n",
    "B05004_002E: This represents the total estimate for the median age of males by nativity and citizenship status.\n",
    "B05004_003E: This represents the total estimate for the median age of females by nativity and citizenship status.\n",
    "B05004_004E: This represents the total estimate for the median age of natives by nativity and citizenship status.\n",
    "B05004_005E: This represents the total estimate for the median age of native males by nativity and citizenship status.\n",
    "B05004_006E: This represents the total estimate for the median age of native females by nativity and citizenship status.\n",
    "B05004_007E: This represents the total estimate for the median age of foreign-born individuals by nativity and citizenship status.\n",
    "B05004_008E: This represents the total estimate for the median age of foreign-born males by nativity and citizenship status\n",
    "B05004_009E: This represents the total estimate for the median age of foreign-born females by nativity and citizenship status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Groups: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B05004_001E', 'B05004_002E', 'B05004_003E', 'B05004_004E', 'B05004_005E']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groups to download from census data\n",
    "groups = [\n",
    "        \"B05004_001E\", \"B05004_002E\", \"B05004_003E\", \n",
    "        \"B05004_004E\", \"B05004_005E\", \"B05004_006E\", \n",
    "        \"B05004_007E\", \"B05004_008E\", \"B05004_009E\",\n",
    "]\n",
    "print(\"# of Groups:\", len(groups))\n",
    "groups[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of URLs: 432\n",
      "['https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_001E&for=tract:*&in=state:56&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_002E&for=tract:*&in=state:56&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_003E&for=tract:*&in=state:56&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_004E&for=tract:*&in=state:56&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_005E&for=tract:*&in=state:56&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_006E&for=tract:*&in=state:56&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_007E&for=tract:*&in=state:56&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_008E&for=tract:*&in=state:56&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:01&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:04&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:05&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:06&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:08&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:09&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:10&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:12&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:13&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:16&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:17&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:18&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:19&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:20&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:21&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:22&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:23&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:24&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:25&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:26&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:27&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:28&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:29&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:30&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:31&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:32&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:33&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:34&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:35&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:36&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:37&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:38&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:39&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:40&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:41&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:42&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:44&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:45&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:46&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:47&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:48&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:49&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:50&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:51&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:53&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:54&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:55&in=county:*', 'https://api.census.gov/data/2019/acs/acs5?get=B05004_009E&for=tract:*&in=state:56&in=county:*']\n"
     ]
    }
   ],
   "source": [
    "# List of URLs for API calls\n",
    "url_list = [\n",
    "    f\"https://api.census.gov/data/2019/acs/acs5?get={group}&for=tract:*&in=state:{state_code}&in=county:*\" \n",
    "    for group in groups \n",
    "    for state_code in state_codes\n",
    "]\n",
    "print(\"# of URLs:\", len(url_list))\n",
    "print(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "432it [06:19,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Successful Responses: 432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_tract</th>\n",
       "      <th>group</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01073001100</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01073001400</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>44.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01073002000</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01073003802</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>35.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01073004000</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>52.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>01077010400</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>01077011300</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>01077011602</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>01077010200</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>40.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>01097004900</td>\n",
       "      <td>B05004_001E</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1181 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0    census_tract        group value\n",
       "1     01073001100  B05004_001E  39.0\n",
       "2     01073001400  B05004_001E  44.3\n",
       "3     01073002000  B05004_001E  34.0\n",
       "4     01073003802  B05004_001E  35.8\n",
       "5     01073004000  B05004_001E  52.1\n",
       "...           ...          ...   ...\n",
       "1177  01077010400  B05004_001E  32.4\n",
       "1178  01077011300  B05004_001E  39.4\n",
       "1179  01077011602  B05004_001E  43.8\n",
       "1180  01077010200  B05004_001E  40.1\n",
       "1181  01097004900  B05004_001E  29.9\n",
       "\n",
       "[1181 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "list_of_dfs = []\n",
    "\n",
    "# Iterate over the list of URLs\n",
    "for idx, url in tqdm(enumerate(url_list)):\n",
    "    # Make API call\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the API call is successful\n",
    "    if response.status_code == 200:\n",
    "        # Convert JSON response to DataFrame\n",
    "        df_tmp = pd.DataFrame(response.json())\n",
    "        \n",
    "        # Set the column names to the first row\n",
    "        df_tmp.columns = df_tmp.iloc[0]\n",
    "        \n",
    "        # Extract the group name from the first column\n",
    "        group = df_tmp.columns.tolist()[0]\n",
    "        \n",
    "        # Remove the first row (header row)\n",
    "        df_tmp = df_tmp.iloc[1:,]\n",
    "        \n",
    "        # Combine state, county, and tract to create census tract identifier\n",
    "        df_tmp[\"census_tract\"] = df_tmp[\"state\"] + df_tmp[\"county\"] + df_tmp[\"tract\"]\n",
    "        \n",
    "        # Add the group name as a new column\n",
    "        df_tmp[\"group\"] = group            \n",
    "        \n",
    "        # Rename the group column to \"value\"\n",
    "        df_tmp.rename(columns = {group: \"value\"}, inplace=True)\n",
    "        \n",
    "        # Reorder the columns\n",
    "        df_tmp = df_tmp[[\"census_tract\", \"group\", \"value\"]]\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        list_of_dfs.append(df_tmp)        \n",
    "    else:\n",
    "        # Print error message if API call is unsuccessful\n",
    "        print(\"Index:\", str(idx+1).zfill(2), \"/ Error Code:\", response.status_code, \"/ URL:\", url)\n",
    "\n",
    "# Print the number of successful responses\n",
    "print(\"# of Successful Responses:\", len(list_of_dfs))\n",
    "\n",
    "# Display the first DataFrame in the list\n",
    "list_of_dfs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all API calls into one dataframe\n",
    "df_median_age = pd.concat(list_of_dfs)\n",
    "df_median_age[\"value\"] = df_median_age[\"value\"].astype(float)\n",
    "df_median_age = df_median_age.pivot_table(\n",
    "    values=\"value\", \n",
    "    index=df_median_age[\"census_tract\"], \n",
    "    columns=\"group\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_tract</th>\n",
       "      <th>all_total</th>\n",
       "      <th>all_males</th>\n",
       "      <th>all_females</th>\n",
       "      <th>native_total</th>\n",
       "      <th>native_males</th>\n",
       "      <th>native_females</th>\n",
       "      <th>foreign_born_total</th>\n",
       "      <th>foreign_born_males</th>\n",
       "      <th>foreign_born_females</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001020100</td>\n",
       "      <td>38.9000</td>\n",
       "      <td>36.8000</td>\n",
       "      <td>40.1000</td>\n",
       "      <td>38.7000</td>\n",
       "      <td>36.6000</td>\n",
       "      <td>39.9000</td>\n",
       "      <td>43.2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001020200</td>\n",
       "      <td>41.3000</td>\n",
       "      <td>34.1000</td>\n",
       "      <td>44.6000</td>\n",
       "      <td>41.2000</td>\n",
       "      <td>34.1000</td>\n",
       "      <td>44.2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001020300</td>\n",
       "      <td>37.6000</td>\n",
       "      <td>37.2000</td>\n",
       "      <td>40.1000</td>\n",
       "      <td>37.3000</td>\n",
       "      <td>37.2000</td>\n",
       "      <td>38.1000</td>\n",
       "      <td>57.5000</td>\n",
       "      <td>59.1000</td>\n",
       "      <td>57.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01001020400</td>\n",
       "      <td>45.8000</td>\n",
       "      <td>42.5000</td>\n",
       "      <td>47.9000</td>\n",
       "      <td>47.3000</td>\n",
       "      <td>45.1000</td>\n",
       "      <td>47.8000</td>\n",
       "      <td>36.7000</td>\n",
       "      <td>36.6000</td>\n",
       "      <td>61.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01001020500</td>\n",
       "      <td>34.9000</td>\n",
       "      <td>32.5000</td>\n",
       "      <td>35.9000</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>33.1000</td>\n",
       "      <td>34.4000</td>\n",
       "      <td>43.9000</td>\n",
       "      <td>24.9000</td>\n",
       "      <td>44.8000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  census_tract  all_total  all_males  all_females  native_total  native_males  \\\n",
       "0  01001020100    38.9000    36.8000      40.1000       38.7000       36.6000   \n",
       "1  01001020200    41.3000    34.1000      44.6000       41.2000       34.1000   \n",
       "2  01001020300    37.6000    37.2000      40.1000       37.3000       37.2000   \n",
       "3  01001020400    45.8000    42.5000      47.9000       47.3000       45.1000   \n",
       "4  01001020500    34.9000    32.5000      35.9000       34.0000       33.1000   \n",
       "\n",
       "   native_females  foreign_born_total  foreign_born_males  \\\n",
       "0         39.9000             43.2000                 NaN   \n",
       "1         44.2000                 NaN                 NaN   \n",
       "2         38.1000             57.5000             59.1000   \n",
       "3         47.8000             36.7000             36.6000   \n",
       "4         34.4000             43.9000             24.9000   \n",
       "\n",
       "   foreign_born_females  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2               57.5000  \n",
       "3               61.4000  \n",
       "4               44.8000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "df_median_age.columns = [\n",
    "\"all_total\", \"all_males\", \"all_females\", \n",
    "\"native_total\", \"native_males\", \"native_females\", \n",
    "\"foreign_born_total\", \"foreign_born_males\", \"foreign_born_females\",\n",
    "]\n",
    "\n",
    "# Replace anything <=0 with NaN\n",
    "df_median_age[df_median_age < 0] = 0\n",
    "df_median_age.replace(0, np.nan, inplace=True)\n",
    "df_median_age = df_median_age.reset_index()\n",
    "\n",
    "# Confirm data types\n",
    "df_median_age[\"census_tract\"] = df_median_age[\"census_tract\"].astype(str).str.zfill(11)\n",
    "df_median_age.iloc[:, 1:] = df_median_age.iloc[:, 1:].astype(float)\n",
    "\n",
    "df_median_age.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Summary\n",
    "Domain knowledge is critical in deciding what types of features you want to include in your initial dataset. Depending on what problem you're trying to solve you will naturally be interested in enriching your data with the most relevant features. US census data focuses on statistics related to people but does not have much industry-specific information, so you'll need to extract and append that data from other sources.\n",
    "\n",
    "For example, if you are interested in the US housing market and differences in pricing, you will want to add features related to properties such as number of beds/baths/rooms/stories, square footage, construction type, exterior material, quality grade, year built, replacement cost, etc.\n",
    "\n",
    "We'll be limiting ourselves to using data from the US census in this exercise. Given that we aren't including other features in addition to the census data our algorithms will cluster based on general demographic information only. To that end we pulled reports from several groups using the methodology outlined above, and combined them into the attached dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Exploratory Data Analysis (EDA)\n",
    "We aim to cluster census tracts with a reasonable level of success. We'll touch on a couple of ways to define \"success\" in this context - and the pros / cons of each method - later in the exercise. As with any data science research project the first step is to get an understanding of what our data looks like: which features it contains, what those features look like, and if we can identify features most in need of further manipulation.\n",
    "\n",
    "Let's start by reading in our dataset as a Pandas dataframe, with the rows representing census tracts and the columns representing various features from the US census API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.4f\" % x)\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data file\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "filepath = cwd + \"/data/acs_demographic_data_by_census_tract.csv\"\n",
    "df = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72050, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>total_homes</th>\n",
       "      <th>total_owned</th>\n",
       "      <th>pct_owned_of_total</th>\n",
       "      <th>15-34_pct_of_owned</th>\n",
       "      <th>35-64_pct_of_owned</th>\n",
       "      <th>65+_pct_of_owned</th>\n",
       "      <th>2017+_pct_of_owned</th>\n",
       "      <th>2015-16_pct_of_owned</th>\n",
       "      <th>2010-14_pct_of_owned</th>\n",
       "      <th>2000-09_pct_of_owned</th>\n",
       "      <th>1990-99_pct_of_owned</th>\n",
       "      <th>1989-_pct_of_owned</th>\n",
       "      <th>median_age_all_total</th>\n",
       "      <th>median_age_all_males</th>\n",
       "      <th>median_age_all_females</th>\n",
       "      <th>median_age_native_total</th>\n",
       "      <th>median_age_native_males</th>\n",
       "      <th>median_age_native_females</th>\n",
       "      <th>median_age_foreign_born_total</th>\n",
       "      <th>median_age_foreign_born_males</th>\n",
       "      <th>median_age_foreign_born_females</th>\n",
       "      <th>median_age_workers_total</th>\n",
       "      <th>median_age_workers_males</th>\n",
       "      <th>median_age_workers_females</th>\n",
       "      <th>total_population</th>\n",
       "      <th>total_income</th>\n",
       "      <th>total_income_per_cap</th>\n",
       "      <th>avg_commute_in_minutes</th>\n",
       "      <th>pct_voting_age_citizens</th>\n",
       "      <th>pct_employed</th>\n",
       "      <th>pct_men</th>\n",
       "      <th>pct_poverty_all</th>\n",
       "      <th>pct_poverty_child</th>\n",
       "      <th>field_pct_professional</th>\n",
       "      <th>field_pct_service</th>\n",
       "      <th>field_pct_office</th>\n",
       "      <th>field_pct_construction</th>\n",
       "      <th>field_pct_production</th>\n",
       "      <th>commute_pct_drive</th>\n",
       "      <th>commute_pct_carpool</th>\n",
       "      <th>commute_pct_transit</th>\n",
       "      <th>commute_pct_walk</th>\n",
       "      <th>commute_pct_other</th>\n",
       "      <th>commute_pct_work_from_home</th>\n",
       "      <th>work_pct_private</th>\n",
       "      <th>work_pct_public</th>\n",
       "      <th>work_pct_self_employed</th>\n",
       "      <th>work_pct_unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>765.0000</td>\n",
       "      <td>570</td>\n",
       "      <td>0.7451</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.4281</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>40.5000</td>\n",
       "      <td>37.7000</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>40.3000</td>\n",
       "      <td>36.6000</td>\n",
       "      <td>44.1000</td>\n",
       "      <td>43.5000</td>\n",
       "      <td>56.2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.6000</td>\n",
       "      <td>39.5000</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>1845.0000</td>\n",
       "      <td>67826.0000</td>\n",
       "      <td>33018.0000</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.4873</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>719.0000</td>\n",
       "      <td>464</td>\n",
       "      <td>0.6453</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.3298</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.2996</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>34.6000</td>\n",
       "      <td>43.9000</td>\n",
       "      <td>41.7000</td>\n",
       "      <td>34.6000</td>\n",
       "      <td>43.8000</td>\n",
       "      <td>55.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.9000</td>\n",
       "      <td>43.9000</td>\n",
       "      <td>44.8000</td>\n",
       "      <td>43.4000</td>\n",
       "      <td>2172.0000</td>\n",
       "      <td>41287.0000</td>\n",
       "      <td>18996.0000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>0.3923</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7590</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>01001020300</td>\n",
       "      <td>1296.0000</td>\n",
       "      <td>841</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.5101</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.1736</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>34.6000</td>\n",
       "      <td>37.1000</td>\n",
       "      <td>34.1000</td>\n",
       "      <td>34.5000</td>\n",
       "      <td>36.9000</td>\n",
       "      <td>33.7000</td>\n",
       "      <td>57.8000</td>\n",
       "      <td>59.1000</td>\n",
       "      <td>57.6000</td>\n",
       "      <td>34.7000</td>\n",
       "      <td>37.3000</td>\n",
       "      <td>34.2000</td>\n",
       "      <td>3385.0000</td>\n",
       "      <td>46806.0000</td>\n",
       "      <td>21236.0000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.4529</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2790</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>1639.0000</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>0.1244</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.3788</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.3304</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.3178</td>\n",
       "      <td>46.4000</td>\n",
       "      <td>42.1000</td>\n",
       "      <td>49.3000</td>\n",
       "      <td>45.8000</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>48.1000</td>\n",
       "      <td>50.1000</td>\n",
       "      <td>48.2000</td>\n",
       "      <td>50.4000</td>\n",
       "      <td>43.2000</td>\n",
       "      <td>41.3000</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>4267.0000</td>\n",
       "      <td>55895.0000</td>\n",
       "      <td>28068.0000</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>4174.0000</td>\n",
       "      <td>2321</td>\n",
       "      <td>0.5561</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.2301</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>36.4000</td>\n",
       "      <td>35.8000</td>\n",
       "      <td>37.2000</td>\n",
       "      <td>35.9000</td>\n",
       "      <td>35.8000</td>\n",
       "      <td>36.1000</td>\n",
       "      <td>37.9000</td>\n",
       "      <td>37.1000</td>\n",
       "      <td>56.7000</td>\n",
       "      <td>39.2000</td>\n",
       "      <td>40.1000</td>\n",
       "      <td>38.4000</td>\n",
       "      <td>9965.0000</td>\n",
       "      <td>68143.0000</td>\n",
       "      <td>36905.0000</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>0.4804</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state census_tract  total_homes  total_owned  pct_owned_of_total  \\\n",
       "0    AL  01001020100     765.0000          570              0.7451   \n",
       "1    AL  01001020200     719.0000          464              0.6453   \n",
       "2    AL  01001020300    1296.0000          841              0.6489   \n",
       "3    AL  01001020400    1639.0000         1262              0.7700   \n",
       "4    AL  01001020500    4174.0000         2321              0.5561   \n",
       "\n",
       "   15-34_pct_of_owned  35-64_pct_of_owned  65+_pct_of_owned  \\\n",
       "0              0.1017              0.6491            0.2492   \n",
       "1              0.0732              0.5970            0.3298   \n",
       "2              0.1962              0.5101            0.2937   \n",
       "3              0.1244              0.4968            0.3788   \n",
       "4              0.0870              0.6829            0.2301   \n",
       "\n",
       "   2017+_pct_of_owned  2015-16_pct_of_owned  2010-14_pct_of_owned  \\\n",
       "0              0.0088                0.0298                0.1210   \n",
       "1              0.0237                0.0151                0.1573   \n",
       "2              0.0666                0.0809                0.0761   \n",
       "3              0.0182                0.0848                0.1403   \n",
       "4              0.0241                0.0698                0.1478   \n",
       "\n",
       "   2000-09_pct_of_owned  1990-99_pct_of_owned  1989-_pct_of_owned  \\\n",
       "0                0.4281                0.2860              0.1263   \n",
       "1                0.2996                0.1121              0.3922   \n",
       "2                0.3674                0.1736              0.2354   \n",
       "3                0.3304                0.1085              0.3178   \n",
       "4                0.5174                0.1840              0.0569   \n",
       "\n",
       "   median_age_all_total  median_age_all_males  median_age_all_females  \\\n",
       "0               40.5000               37.7000                 43.0000   \n",
       "1               42.0000               34.6000                 43.9000   \n",
       "2               34.6000               37.1000                 34.1000   \n",
       "3               46.4000               42.1000                 49.3000   \n",
       "4               36.4000               35.8000                 37.2000   \n",
       "\n",
       "   median_age_native_total  median_age_native_males  \\\n",
       "0                  40.3000                  36.6000   \n",
       "1                  41.7000                  34.6000   \n",
       "2                  34.5000                  36.9000   \n",
       "3                  45.8000                  42.0000   \n",
       "4                  35.9000                  35.8000   \n",
       "\n",
       "   median_age_native_females  median_age_foreign_born_total  \\\n",
       "0                    44.1000                        43.5000   \n",
       "1                    43.8000                        55.5000   \n",
       "2                    33.7000                        57.8000   \n",
       "3                    48.1000                        50.1000   \n",
       "4                    36.1000                        37.9000   \n",
       "\n",
       "   median_age_foreign_born_males  median_age_foreign_born_females  \\\n",
       "0                        56.2000                              NaN   \n",
       "1                            NaN                          55.9000   \n",
       "2                        59.1000                          57.6000   \n",
       "3                        48.2000                          50.4000   \n",
       "4                        37.1000                          56.7000   \n",
       "\n",
       "   median_age_workers_total  median_age_workers_males  \\\n",
       "0                   43.6000                   39.5000   \n",
       "1                   43.9000                   44.8000   \n",
       "2                   34.7000                   37.3000   \n",
       "3                   43.2000                   41.3000   \n",
       "4                   39.2000                   40.1000   \n",
       "\n",
       "   median_age_workers_females  total_population  total_income  \\\n",
       "0                     46.9000         1845.0000    67826.0000   \n",
       "1                     43.4000         2172.0000    41287.0000   \n",
       "2                     34.2000         3385.0000    46806.0000   \n",
       "3                     47.1000         4267.0000    55895.0000   \n",
       "4                     38.4000         9965.0000    68143.0000   \n",
       "\n",
       "   total_income_per_cap  avg_commute_in_minutes  pct_voting_age_citizens  \\\n",
       "0            33018.0000                 25.0000                   0.7626   \n",
       "1            18996.0000                 22.0000                   0.7606   \n",
       "2            21236.0000                 23.0000                   0.7326   \n",
       "3            28068.0000                 26.0000                   0.7633   \n",
       "4            36905.0000                 21.0000                   0.7254   \n",
       "\n",
       "   pct_employed  pct_men  pct_poverty_all  pct_poverty_child  \\\n",
       "0        0.4775   0.4873           0.1070             0.2080   \n",
       "1        0.3923   0.5373           0.2240             0.3580   \n",
       "2        0.4378   0.4529           0.1470             0.2110   \n",
       "3        0.4333   0.4689           0.0230             0.0170   \n",
       "4        0.4804   0.5072           0.1220             0.1790   \n",
       "\n",
       "   field_pct_professional  field_pct_service  field_pct_office  \\\n",
       "0                  0.3850             0.1560            0.2280   \n",
       "1                  0.3050             0.2490            0.2290   \n",
       "2                  0.2790             0.1940            0.3330   \n",
       "3                  0.2900             0.1660            0.2580   \n",
       "4                  0.4880             0.1380            0.2050   \n",
       "\n",
       "   field_pct_construction  field_pct_production  commute_pct_drive  \\\n",
       "0                  0.1080                0.1240             0.9420   \n",
       "1                  0.0630                0.1540             0.9050   \n",
       "2                  0.0990                0.0960             0.8830   \n",
       "3                  0.0910                0.1950             0.8230   \n",
       "4                  0.0350                0.1340             0.8690   \n",
       "\n",
       "   commute_pct_carpool  commute_pct_transit  commute_pct_walk  \\\n",
       "0               0.0330               0.0000            0.0050   \n",
       "1               0.0910               0.0000            0.0000   \n",
       "2               0.0840               0.0000            0.0100   \n",
       "3               0.1120               0.0000            0.0150   \n",
       "4               0.1120               0.0000            0.0080   \n",
       "\n",
       "   commute_pct_other  commute_pct_work_from_home  work_pct_private  \\\n",
       "0             0.0000                      0.0210            0.7420   \n",
       "1             0.0050                      0.0000            0.7590   \n",
       "2             0.0080                      0.0150            0.7330   \n",
       "3             0.0290                      0.0210            0.7580   \n",
       "4             0.0030                      0.0070            0.7140   \n",
       "\n",
       "   work_pct_public  work_pct_self_employed  work_pct_unemployed  \n",
       "0           0.2120                  0.0450               0.0460  \n",
       "1           0.1500                  0.0900               0.0340  \n",
       "2           0.2110                  0.0480               0.0470  \n",
       "3           0.1970                  0.0450               0.0610  \n",
       "4           0.2410                  0.0450               0.0230  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# All columns in lower case\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# Census tract 11 characters long\n",
    "df[\"census_tract\"] = df[\"census_tract\"].astype(str).str.zfill(11)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains 50 columns, the first two of which are state and census tract (dtype=\"object\"). It also has a row for every census tract except for ~2K of them which are located in US territories or Washington D.C.\n",
    "\n",
    "The remaining 48 features are numerical (dtype=\"float\") with various ranges and distributions, but we can already see opportunities for combining and/or removing some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. States Selection\n",
    "In this exercise we are not interested in looking at low-density, relatively homogeneous states in Middle America. Instead we'd like to identify census tract similarity and diversity based on the features in our dataset. We want to focus on states which are not exclusively rural but include big cities (such as California, New York or Texas) as well.\n",
    "\n",
    "Let's identify the states with the most census tracts and focus on the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states_to_keep = 10\n",
    "\n",
    "num_tracts_df = df[\"state\"].value_counts(normalize=False).reset_index()\n",
    "pct_tracts_df = df[\"state\"].value_counts(normalize=True).reset_index()\n",
    "tracts_df = pd.merge(num_tracts_df, pct_tracts_df, how=\"inner\", on=\"index\")\n",
    "\n",
    "tracts_df.columns = [\"state\", \"num_tracts\", \"pct_tracts\"]\n",
    "tracts_df[\"cumsum_num_tracts\"] = tracts_df[\"num_tracts\"].cumsum()\n",
    "tracts_df[\"cumsum_pct_tracts\"] = tracts_df[\"pct_tracts\"].cumsum()\n",
    "\n",
    "tracts_df.head(num_states_to_keep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of states\n",
    "states_to_keep = tracts_df[\"state\"].head(num_states_to_keep).values\n",
    "states_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset only includes census tracts from \"dense\" states\n",
    "df = df[df[\"state\"].isin(states_to_keep)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that just 10 states contain more than half the census tracts.\n",
    " Although here we'll limit our clustering to these 10 states, in theory wecould cluster however we'd like and see what the output is (e.g. just one state, all 50 states, anything in between).\n",
    "\n",
    "## B. Combine & Drop Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"2010+_pct_of_owned\"] = df[\"2010-14_pct_of_owned\"] + df[\"2015-16_pct_of_owned\"] + df[\"2017+_pct_of_owned\"]\n",
    "df[\"commute_pct_car\"] = df[\"commute_pct_drive\"] + df[\"commute_pct_carpool\"]\n",
    "df[\"work_pct_other\"] = df[\"work_pct_self_employed\"] + df[\"work_pct_unemployed\"]\n",
    "df[\"total_home_to_pop_ratio\"] = df[\"total_population\"] / df[\"total_homes\"]\n",
    "df[\"total_income_to_per_cap_ratio\"] = df[\"total_income\"] / df[\"total_income_per_cap\"]\n",
    "df[\"median_age_males_females_pct_diff\"] = (df[\"median_age_all_males\"] - df[\"median_age_all_females\"]) / df[\"median_age_all_females\"]\n",
    "df[\"median_age_males_females_pct_diff\"] = df[\"median_age_males_females_pct_diff\"] + abs(df[\"median_age_males_females_pct_diff\"].min())\n",
    "\n",
    "age_cols_to_drop = [c for c in df.columns if c[:10] == \"median_age\" and c[-8:] != \"pct_diff\" and c != \"median_age_all_total\"]\n",
    "df.drop(age_cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "df.drop([\"2010-14_pct_of_owned\", \"2015-16_pct_of_owned\", \"2017+_pct_of_owned\", \"2000-09_pct_of_owned\", \"1990-99_pct_of_owned\", \"1989-_pct_of_owned\"], axis=1, inplace=True)\n",
    "df.drop([\"commute_pct_drive\", \"commute_pct_carpool\", \"commute_pct_transit\", \"commute_pct_walk\", \"commute_pct_other\", \"commute_pct_work_from_home\"], axis=1, inplace=True)\n",
    "df.drop([\"work_pct_public\", \"work_pct_self_employed\", \"work_pct_unemployed\"], axis=1, inplace=True)\n",
    "df.drop([\"total_population\", \"total_owned\", \"total_income_per_cap\"], axis=1, inplace=True)\n",
    "df.drop([\"field_pct_service\", \"field_pct_construction\", \"field_pct_production\"], axis=1, inplace=True)\n",
    "df.drop([\"pct_poverty_all\", \"pct_poverty_child\"], axis=1, inplace=True)\n",
    "df.drop([\"65+_pct_of_owned\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update features list\n",
    "features = [\n",
    "    \"total_homes\", \"total_home_to_pop_ratio\", \"total_income_to_per_cap_ratio\", \"pct_owned_of_total\", \"pct_men\",\n",
    "    \"pct_voting_age_citizens\", \"pct_employed\", \"avg_commute_in_minutes\", \"commute_pct_car\", \"work_pct_private\", \n",
    "    \"work_pct_other\", \"field_pct_professional\", \"field_pct_office\", \"median_age_males_females_pct_diff\",\n",
    "    \"median_age_all_total\", \"15-34_pct_of_owned\", \"35-64_pct_of_owned\", \"2010+_pct_of_owned\",\n",
    "]\n",
    "df = df[[\"state\", \"census_tract\"] + features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a better sense of what these features look like by visualizing them. We'll use histograms and boxplots to understand their distributions - mean, median, min, max, outliers, skewness, etc. - and a correlation matrix to determine the dependencies between them.\n",
    "\n",
    "## C. Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(df, features, figsize=(35, 70), num_rows=15, num_cols=5, color=\"#ff0083\", num_bins=25, alpha=0.8, lower=0.025, upper=0.975):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for feature in features:\n",
    "        df_tmp = df.copy()\n",
    "        ax1 = plt.subplot(num_rows, num_cols, features.index(feature) + 1)\n",
    "        df_tmp[feature] = df_tmp[feature].clip(df_tmp[feature].quantile(lower), df_tmp[feature].quantile(upper))\n",
    "        mean = df_tmp[feature].dropna().mean()\n",
    "        median = df_tmp[feature].dropna().median()\n",
    "        \n",
    "        h1 = df_tmp[feature].hist(bins=num_bins, alpha=alpha, align=\"left\", label=f\"{feature} Freq Dist\", color=color,\n",
    "            weights=np.ones_like(df_tmp[feature].dropna()) / len(df_tmp[feature].dropna()))\n",
    "        \n",
    "        l1 = ax1.axvline(x=round(mean, 4), ymax=1, alpha=alpha, linestyle=\"dashed\", label=f\"{feature} Freq Mean\", color=\"#D3D3D3\")\n",
    "        \n",
    "        l2 = ax1.axvline(x=round(median, 4), ymax=1, alpha=alpha, linestyle=\"dashed\", label=f\"{feature} Freq Median\", color=\"#228B22\")\n",
    "        \n",
    "        plt.title(f\"{feature}\", fontsize=20, fontweight=\"bold\")\n",
    "        ax1.title.set_position([0.5, 1.05])\n",
    "        ax1.spines[\"right\"].set_visible(False)\n",
    "        ax1.spines[\"top\"].set_visible(False)\n",
    "        plt.legend(loc=1, frameon=False)\n",
    "        plt.xlim(df_tmp[feature].min(), df_tmp[feature].max())\n",
    "        plt.ylim(0, 0.3)\n",
    "        plt.grid(False)\n",
    "        ax1.set_yticklabels([\"{:,.0%}\".format(x) for x in ax1.get_yticks()])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  D Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, features, figsize=(35, 70), num_rows=15, num_cols=5, show_outliers=True):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for feature in features:\n",
    "        df_tmp = df.copy()\n",
    "        ax1 = plt.subplot(num_rows, num_cols, features.index(feature) + 1)\n",
    "        plt.title(str(feature), fontsize=16, fontweight=\"bold\", y=1.025)\n",
    "        \n",
    "        bp = plt.boxplot([df[(df[feature] >= 0)][feature]], sym=\"g.\", showfliers=show_outliers, showmeans=True,\n",
    "                         medianprops = dict(linestyle=\"-\", linewidth=2, color=\"darkblue\"))\n",
    "        \n",
    "        for flier in bp[\"fliers\"]:\n",
    "            flier.set(marker=\"o\", color=\"y\", alpha=0.1)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Correlation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correl_matrix(df, features, correl_figsize=(30, 20)):\n",
    "    plt.figure(figsize=correl_figsize)\n",
    "    matrix = np.triu(df[features].corr())\n",
    "    sns.heatmap(df[features].corr(), annot=False, cmap=\"RdYlGn\", mask=matrix)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Plot Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\\n",
    "def plot_graphs(df, features):  \n",
    "    plot_hist(df=df, features=features)\n",
    "    plot_box(df=df, features=features)\n",
    "    plot_correl_matrix(df=df, features=features)\n",
    "    \n",
    "# Show histograms, boxplots and correlation matrix\n",
    "plot_graphs(df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the dataframe with preprocessed values for later use\n",
    "df_preprocessed = df.copy()\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles_list = [.025, .05, .25, .50, .75, .95, .975]\n",
    "df.describe(percentiles=percentiles_list).apply(lambda x: x.apply(\"{0:.4f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our EDA accomplished several things:\n",
    "\n",
    "##### 1. Reduces our feature set to 20 features\n",
    "\n",
    "WHY? Later on we'll use an algorithm which is computationally heavy (O^2). Since we already have 72K rows i.e. census tracts we'd like to keep the number of columns i.e. features reasonable to reduce computation time. We also want to avoid the curse of dimensionality.\n",
    "\n",
    "\n",
    "##### 2. Validates our features are uncorrelated\n",
    "\n",
    "WHY? Later on we'll use a popular dimensionality reduction technique to produce orthogonal features and reduce any concerns of high-correlativity. However, some of the features in our initial dataset are highly correlated to begin with, and we can feel confident in removing them already at this stage of the process.\n",
    "\n",
    "#####  3. Removes features with many missing values\n",
    "\n",
    "WHY? Unlike some boosted tree algorithms which know how to account for missing values (e.g. XGBoost or LightGBM), unsupervised clustering algorithms generally don't know how to handle missing data. We therefore either need to remove NaNs or impute other values into our dataset. Later on we'll use iterative imputing to fill the remaining NaNs, but for features that are extremely sparse we'll simply remove them for the sake of this exercise.\n",
    "\n",
    "##### 4. Focuses on features that are well distributed\n",
    "\n",
    "WHY? All the inputs from our dataset are numerical so we prefer data that is more diverse as that will help the algorithm generate distances and clustering more effectively. Some features do have skewness and extreme outliers which will be handled by feature engineering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Feature Engineering\n",
    "There are four main preprocessing steps to perform to enable our unsupervised algorithms to effectively cluster our data:\n",
    "\n",
    "Ensure our features are normally distributed -> Log Transform heavily right/left-skewed features\n",
    "\n",
    "Remove outliers -> identify thresholds using the IQR Method and replace with NaNs\n",
    "\n",
    "Handle algorithms' inherent sensitivity to scale -> apply StandardScaler to remove mean & scale to unit variance\n",
    "\n",
    "Fill out missing values to allow for clustering -> use IterativeImputer with BayesianRidge regression (this includes nulls from original raw data & outliers replaced above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Log Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(df, feature_skew_dict):\n",
    "    for feature, skew in feature_skew_dict.items():\n",
    "        assert df[feature].min() >= 0\n",
    "        if skew == \"right\":\n",
    "            df[feature] = np.log(df[feature] + 1)\n",
    "        elif skew == \"left\":\n",
    "            df[feature] = np.log((max(df[feature] + 1) - df[feature]))\n",
    "            \n",
    "# Apply log transform to heavily skewed features\n",
    "feature_skew_dict = {\n",
    "    \"total_homes\": \"right\",\n",
    "    \"total_home_to_pop_ratio\": \"right\",\n",
    "    \"total_income_to_per_cap_ratio\": \"right\", \n",
    "    \"pct_owned_of_total\": \"left\",\n",
    "    \"commute_pct_car\": \"left\",\n",
    "}\n",
    "\n",
    "log_transform(df, feature_skew_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Outliers (IQR Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outliers(df, features):\n",
    "    for feature in features:\n",
    "        sorted_data = sorted(df[feature].dropna())\n",
    "        q1, q3 = np.percentile(sorted_data, [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        _lower = round(q1 - (1.5 * iqr), 4)\n",
    "        _upper = round(q3 + (1.5 * iqr), 4)\n",
    "        df[feature] = df[feature].apply(lambda x: np.where(x < _lower, np.nan, x))\n",
    "        df[feature] = df[feature].apply(lambda x: np.where(x > _upper, np.nan, x))\n",
    "        outliers_dict[feature] = {\n",
    "            \"min_max\": {\"1_min\": round(df[feature].min(), 4),  \"2_max\": round(df[feature].max(), 4)},\n",
    "            \"iqr_bounds\": {\"1_lower\": _lower, \"2_upper\": _upper}, \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outliers identified via IQR method with NaNs\n",
    "outliers_dict = dict()\n",
    "iqr_outliers(df, features)\n",
    "\n",
    "# pprint(outliers_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(df, features):\n",
    "    z_scored = StandardScaler()\n",
    "    df[features] = z_scored.fit_transform(df[features])\n",
    "    \n",
    "    \n",
    "# Scale all features to a standard normal distribution\n",
    "standard_scale(df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def impute_nans(df, features, method=\"iterative\"):\n",
    "    if method == \"iterative\":\n",
    "            iterative_imputer = IterativeImputer(\n",
    "                missing_values=np.nan,\n",
    "                n_nearest_features=None,\n",
    "                initial_strategy=\"mean\",\n",
    "                imputation_order=\"ascending\",\n",
    "                max_iter=10,                \n",
    "                random_state=42,\n",
    "                verbose=0,\n",
    "            )\n",
    "            df[features] = iterative_imputer.fit_transform(df[features])\n",
    "    else:\n",
    "        simple_imputer = SimpleImputer(\n",
    "            missing_values=np.nan,\n",
    "            strategy=\"mean\",\n",
    "            verbose=0,\n",
    "        )\n",
    "        df[features] = simple_imputer.fit_transform(df[features])\n",
    "        \n",
    "# Fill in NaNs with imputed values\n",
    "impute_nans(df, features, method=\"iterative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph min, median & max values of each feature after they've been feature engineered\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.plot(df.describe().columns.tolist(), df.describe().iloc[5,:], label=\"median\", color=\"black\", linewidth=2, marker=\"o\")\n",
    "plt.bar(df.describe().columns.tolist(), df.describe().iloc[3,:], label=\"minimum\")\n",
    "plt.bar(df.describe().columns.tolist(), df.describe().iloc[-1,:], label=\"maximum\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12, fontweight=\"bold\")\n",
    "plt.ylabel(\"Values\", fontsize=16, fontweight=\"bold\")\n",
    "plt.title(\"Transformed, Scaled, Standardized & Imputed Values\", fontsize=20, fontweight=\"bold\")\n",
    "ax.title.set_position([.5, 1.025])\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Dimensionality Reduction\n",
    "\n",
    "Now that our data is transformed, scaled, standardized & imputed, we'll use Principal Components Analysis (PCA) to generate principal components that are orthogonal to one another and throw away the components which don't add much by way of explainability. We'll see that the initial, low-numbered principal components explain a large amount of variance but - as we'd expect - the additional % of variance explained by later components drops as we increase the total number.\n",
    "\n",
    "What is an acceptable amount of explainability to lose overall? A good rule of thumb is that any components beyond the ones which explain a cumulative 95% of total variance can be discarded. We'll calculate how many principal components we need to reach this threshold, and then reduce our feature set accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Identify Optimal # of PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe into numpy array (allows for faster computation)\n",
    "X = df[features].values\n",
    "pca = PCA(random_state=42)\n",
    "\n",
    "pca.fit(X)\n",
    "PCA(random_state=42)\n",
    "\n",
    "df_pca = pd.DataFrame({\n",
    "    \"principal_component\": range(1, X.shape[1]+1),\n",
    "    \"explained_variance\": pca.explained_variance_ratio_,\n",
    "    \"cumsum_explained_variance\": pca.explained_variance_ratio_.cumsum(),\n",
    "})\n",
    "\n",
    "df_pca.loc[-1] = 0\n",
    "df_pca.sort_values(by=\"principal_component\", inplace=True)\n",
    "\n",
    "print(df_pca.shape)\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(df_pca[\"principal_component\"], df_pca[\"explained_variance\"], marker=\"o\", label=\"Individual Explained Variance\")\n",
    "plt.plot(df_pca[\"principal_component\"], df_pca[\"cumsum_explained_variance\"], marker=\"o\", label=\"Cumulative Explained Variance\")\n",
    "plt.plot(df_pca[\"principal_component\"], [0.95] * len(df_pca), color=\"black\", linewidth=2, linestyle=\"--\", label=\"95% Explained Variance\")\n",
    "ax.set_xticklabels([\"{:,.0f}\".format(x) for x in ax.get_xticks()])\n",
    "ax.set_yticklabels([\"{:,.0%}\".format(x) for x in ax.get_yticks()])\n",
    "plt.title(\"PCA Explained Variance\", fontsize=20, fontweight=\"bold\")\n",
    "ax.title.set_position([.5, 1.025])\n",
    "plt.xticks(range(0,21), range(0,21), fontsize=12, fontweight=\"bold\")\n",
    "plt.yticks(fontsize=12, fontweight=\"bold\")\n",
    "plt.xlabel(\"Principal Component Number\", fontsize=16, fontweight=\"bold\")\n",
    "plt.ylabel(\"% of Explained Variance\", fontsize=16, fontweight=\"bold\")\n",
    "plt.grid(False)\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_pca = int(df_pca[\"cumsum_explained_variance\"].gt(0.95).idxmax())\n",
    "print(\"# of Features Until 95% Variance is Reached:\", n_components_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. PCA Fit & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_components_pca, random_state=42)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. KMeans Clustering\n",
    "\n",
    "In order to determine the optimal number of clusters for the algorithm we'll use the popular Elbow Method where we calculate the Within Cluster Sum of Squares (WCSS) - also known as intertia - for each potential number of clusters we could use. This hyperparameter tuning will help us identify how many clusters to instantiate our KMeans model with.\n",
    "\n",
    "We'll create a Scree Plot where the X-axis maps the number of clusters and the Y-axis maps the inertia. The value of x where the plot forms an \"elbow\" - i.e. the slope change vs. the previous number of clusters reduces the most - is what we'll use for our model.fit_predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Elbow Method (Scree Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of clusters to check\n",
    "inertia_scores = []\n",
    "silhouette_scores = []\n",
    "no_of_clusters = range(2, 22)\n",
    "\n",
    "# Calculate intertia & silhouette average for each cluster\n",
    "for cluster in tqdm(no_of_clusters):\n",
    "    kmeans = KMeans(n_clusters=cluster, init=\"k-means++\", random_state=42)\n",
    "    kmeans = kmeans.fit(X)\n",
    "    \n",
    "    inertia = kmeans.inertia_\n",
    "    silhouette_avg = silhouette_score(X, kmeans.labels_)\n",
    "    \n",
    "    inertia_scores.append(round(inertia))\n",
    "    silhouette_scores.append(silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interia scree plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(range(1, len(no_of_clusters)+1), inertia_scores, marker=\"o\", linewidth=2, linestyle=\"--\")\n",
    "plt.xticks(range(1, len(no_of_clusters)+1), no_of_clusters, fontsize=12, fontweight=\"bold\")\n",
    "ax.set_yticklabels([\"{:,.0f}\".format(x/1000) + \"K\" for x in ax.get_yticks()])\n",
    "plt.yticks(fontsize=12, fontweight=\"bold\")\n",
    "plt.xlabel(\"# of Clusters\", fontsize=16, fontweight=\"bold\")\n",
    "plt.ylabel(\"Inertia\", fontsize=16, fontweight=\"bold\")\n",
    "plt.title(\"Inertia Scree Plot per Cluster\", fontsize=20, fontweight=\"bold\")\n",
    "ax.title.set_position([.5, 1.025])\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes = [0]\n",
    "slopes_pct_change = []\n",
    "inertia_df = pd.DataFrame()\n",
    "inertia_df[\"inertia\"] = inertia_scores\n",
    "inertia_df[\"n_clusters\"] = inertia_df.index + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_calc(df, x_field, y_field):\n",
    "    x_values = df[x_field].values\n",
    "    y_values = df[y_field].values\n",
    "    for i in range(1, len(x_values)):\n",
    "        (x1, y1) = (x_values[i-1], y_values[i-1])\n",
    "        (x2, y2) = (x_values[i], y_values[i])\n",
    "        slope = round((y2 - y1) / (x2 - x1), 4)\n",
    "        slopes.append(slope)\n",
    "        slopes_pct_change.append((abs(slopes[i-1]) - abs(slopes[i])) / abs(slopes[i-1]))\n",
    "    df[\"slopes\"] = slopes\n",
    "    df[\"slopes_pct_change\"] = slopes_pct_change + [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimal number of clusters\n",
    "derivative_calc(inertia_df, \"n_clusters\", \"inertia\")\n",
    "n_clusters_kmeans = int(inertia_df.loc[inertia_df[\"slopes_pct_change\"].idxmax()][\"n_clusters\"])\n",
    "print(\"# of Clusters for KMeans Algorithm:\", n_clusters_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia_df[[\"n_clusters\", \"inertia\", \"slopes\", \"slopes_pct_change\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Model Fit & Predict¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters_kmeans, init=\"k-means++\", random_state=42)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "def cluster_cnts(predictions, algorithm):\n",
    "    \n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    cluster_cnts_df = pd.DataFrame(counts)\n",
    "    cluster_cnts_df[\"ratio\"] = round(100 * cluster_cnts_df[0] / cluster_cnts_df[0].sum(), 4)\n",
    "    cluster_cnts_df = cluster_cnts_df.reset_index()\n",
    "    cluster_cnts_df.columns = [\"cluster\", \"count\", \"ratio\"]\n",
    "    \n",
    "    print(f\"Breakdown of Census Tracts in Each {algorithm} Cluster\")\n",
    "    return cluster_cnts_df\n",
    "\n",
    "cluster_cnts(y_kmeans, \"KMeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_kmeans_euclidean = round(silhouette_score(X, y_kmeans, metric=\"euclidean\"), 4)\n",
    "silhouette_kmeans_manhattan = round(silhouette_score(X, y_kmeans, metric=\"manhattan\"), 4)\n",
    "print(\"Silhouette Score KMeans Euclidean:\", silhouette_kmeans_euclidean, \"\\nSilhouette Score KMeans Manhattan:\", silhouette_kmeans_manhattan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The silhouette score is a metric between [-1, 1] that incorporates the mean intra-cluster distance and mean nearest-cluster distance. A score of 1 means the clusters are dense and nicely separated i.e. the mean intra-cluster distance is large and the mean nearest-cluster distance is small. A score of 0 means the cluster boundaries may be overlapping i.e the mean intra-cluster distance is small and the mean nearest-cluster distance is large. A score of -1 means that samples likely got assigned to the wrong clusters, and we need to revisit the data.\n",
    "\n",
    "\n",
    "It is inherently difficult to assess the performance of unsupervised algorithms since by definition we don't know what the truth value we're looking to identify actually is. Silhouette score is a good option, but suffers from a couple of major drawbacks. One is that it's problematic to compare between different algorithms using it as a benchmark, so a lower silhouette score in, say, Agglomerative vs. KMeans is not necessarily conclusive. Additionally, increasing the volume of the data will almost always decrease this score, since there is more variability in the data and hence a lower likelihood for a \"perfect\" clustering to be possible.\n",
    "\n",
    "\n",
    "Out dataset contains tens of thousands of rows, making a high silhouette score a near impossibility (even if we had more and/or better features to work with). For this exercise, however, we have another recourse to assess the algorithms' performance. The clustering is agnostic to the meaning of a census tract; all it knows are the associated features. Since we have a intuitive idea of what areas in the states we selected should be \"similar\", we can visualize the census tracts on a map, color-code them according to cluster, and see if the result aligns with what we'd expect to find. We will do this later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Example\n",
    "\n",
    "Let's choose two random principal components to graph to assess if clearly defined clusters are evident (since we can only visualize in 2D or 3D we cannot \"see\" the clusters in this way for all 15 Principal Components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(X, y, features_to_compare, algorithm, is_kmeans=True):\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    plt.scatter(X[y == 0, features_to_compare[0]], X[y == 0, features_to_compare[1]], s=25, c=\"red\", alpha=0.8, label=\"Cluster 0\")\n",
    "    plt.scatter(X[y == 1, features_to_compare[0]], X[y == 1, features_to_compare[1]], s=25, c=\"yellow\", alpha=0.6, label=\"Cluster 1\")\n",
    "    plt.scatter(X[y == 2, features_to_compare[0]], X[y == 2, features_to_compare[1]], s=25, c=\"green\", alpha=0.4, label=\"Cluster 2\")\n",
    "    plt.scatter(X[y == 3, features_to_compare[0]], X[y == 3, features_to_compare[1]], s=25, c=\"blue\", alpha=0.2, label=\"Cluster 3\")\n",
    "    \n",
    "    if is_kmeans:\n",
    "        plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=200, c=\"black\", marker=\"^\", label=\"Centroid\")\n",
    "    \n",
    "    plt.title(f\"PCA Components {features_to_compare[0]} vs {features_to_compare[1]} {algorithm}\", fontsize=20, fontweight=\"bold\")\n",
    "    ax.title.set_position([.5, 1.025])\n",
    "    plt.legend(loc=\"best\", frameon=False)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(X=X, y=y_kmeans, features_to_compare=[1, 11], algorithm=\"KMeans\", is_kmeans=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Agglomerative Clustering\n",
    "\n",
    "A major advantage of Agglomerative clustering over KMeans is that you don't have to provide the number of clusters as a hyperparameter. By graphing a dendrogram - which is basically a visualization of the clustering technique used by this algorithm - we can determine this number via the following:\n",
    "\n",
    "Identify which section of the dendrogram has the largest vertical distance where there is no new \"branching off\" that occurs\n",
    "Draw a horizontal line through that section of the dendrogram from one end to the other\n",
    "Count the number of vertical lines that intersect the horizontal line\n",
    "Another advantage of Agglomerative is that it has a unique result; no matter how many times we run the algorithm it always produces the same dendrogram (assuming no changes are made to the data). This is in contrast to KMeans where without a random state defining the initial centroid locations the final results could vary with each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from scipy.cluster import hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method=\"ward\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dendrogram indicates our data is most naturally divided into two clusters, as the distance between 250 and 350 is the largest vertical distance uninterrupted by a split and it contains just two trees within it. This makes sense for a couple of reasons:\n",
    "\n",
    "Our original features are not very interesting in the sense that generic population stats don't have any domain-related \"nuance\"\n",
    "It is natural to divide geographic areas into two broad categories: urban and rural\n",
    "The dendrogram's recommendation notwithstanding, we'll use four clusters here as well to be consistent with our choice for KMeans and to provide more color in our final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimal number of clusters based on dendrogram\n",
    "n_clusters_agglom = 4\n",
    "print(\"# of Clusters for Agglomerative Algorithm:\", n_clusters_agglom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Model Fit & Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglom = AgglomerativeClustering(n_clusters=n_clusters_agglom, affinity=\"euclidean\", linkage=\"ward\")\n",
    "y_agglom = agglom.fit_predict(X)\n",
    "cluster_cnts(y_agglom, \"Agglomerative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_agglom_euclidean = round(silhouette_score(X, y_agglom, metric=\"euclidean\"), 4)\n",
    "silhouette_agglom_manhattan = round(silhouette_score(X, y_agglom, metric=\"manhattan\"), 4)\n",
    "print(\"Silhouette Score Agglomerative Euclidean:\", silhouette_agglom_euclidean, \"\\nSilhouette Score Agglomerative Manhattan:\", silhouette_agglom_manhattan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Example\n",
    "\n",
    "Unlike the KMeans algorithm, the Agglomerative algorithm's scatter plot does not include centroids. This is because the algorithm doesn't use centroids to determine its clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(X=X, y=y_agglom, features_to_compare=[1, 11], algorithm=\"Agglomerative\", is_kmeans=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIII. Cluster Profiles\n",
    "\n",
    "Now that we have our predictions, we'd like to include the prediction responses in our preprocessed Pandas dataframe, and try to understand what is unique about each cluster. We can then create a \"profile\" for each cluster, and visualize the census tracts on a heatmap of the US.\n",
    "\n",
    "#### A. Calculate Average Values for each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed[\"kmeans_pred\"] = y_kmeans\n",
    "df_preprocessed[\"agglom_pred\"] = y_agglom\n",
    "df_all_kmeans_avgs = df_preprocessed.groupby(\"kmeans_pred\").mean().reset_index()[[\"kmeans_pred\"] + features]\n",
    "df_all_agglom_avgs = df_preprocessed.groupby(\"agglom_pred\").mean().reset_index()[[\"agglom_pred\"] + features]\n",
    "df_all_kmeans_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_agglom_avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Plot Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(df, group_col):\n",
    "    fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    for idx, f in enumerate(df.columns[1:]):\n",
    "        ax1 = plt.subplot(4, 5, idx+1)\n",
    "        plt.bar(df[group_col], df[f], alpha=0.8)\n",
    "        plt.ylim(df[f].min() * 0.8, df[f].max() * 1.2)\n",
    "        plt.title(f, fontsize=16, fontweight=\"bold\")\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.grid(False)\n",
    "    \n",
    "        labels = round(df[f], 2).values.tolist()\n",
    "        for rect, label in zip(ax1.patches, labels):\n",
    "            height = rect.get_height()\n",
    "            ax1.text(rect.get_x() + rect.get_width() / 2, height + 0.05, label, ha=\"center\", va=\"bottom\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_bar(df_all_kmeans_avgs, \"kmeans_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most interesting insight here is that some features are more meaningful than others. For example, the feature pct_men seems relatively unimpactful, while the feature total_income_to_per_cap_ratio clusters two groups very differently than the other two. Unsupervised clustering algorithms such as KMeans assume equal weight to all the features they are provided with as they are simply calculating distance irrespective of the \"importance\" a feature actually has. This can negatively affect its desired performance when some features should be more heavily accounted for than others. These results indicate that we should rethink how critical some of the 20 features we used really are.\n",
    "\n",
    "Let's also get a sense of each cluster's characteristics by calculating the rank for each feature and comparing between them.\n",
    "\n",
    "### C. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace mean value with rank relative to all the clusters (1 = lowest, 4 = higheest)\n",
    "for col in df_all_kmeans_avgs.columns:\n",
    "    df_all_kmeans_avgs[col] = df_all_kmeans_avgs[col].rank()\n",
    "    \n",
    "# Show as Pandas dataframe\n",
    "cluster_profiles_df = df_all_kmeans_avgs.T\n",
    "cluster_profiles_df = cluster_profiles_df.astype(int).reset_index()\n",
    "cluster_profiles_df.columns = [\"Features\", \"Cluster 0\", \"Cluster 1\", \"Cluster 2\", \"Cluster 3\"]\n",
    "\n",
    "print(cluster_profiles_df.iloc[:, 1:].sum())\n",
    "cluster_profiles_df.iloc[1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can do the heat map in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. Conclusion\n",
    "\n",
    "In this notebook we built a pipeline designed to address every step of creating a clustering model, from gathering and exploring the data to manipulating and refining it to actually generating the clusters to (finally) understanding and validating them. We'd like to stress that the actual results of this exercise would be greatly improved by significantly expanding our initial feature set from both a quantitative (the silhouette scores could be higher) and qualitative (the heatmap has patches which seem \"off\") perspective. However, our main goal was to demonstrate a methodology which can be adapted and used in various practical applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
